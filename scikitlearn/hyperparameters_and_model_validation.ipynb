{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hyperparameters and Model validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In the previous section, we saw the basic recipe of applying a supervised machine learning model:\n",
    "\n",
    "1. Choose a class of model \n",
    "2. Choose model hyperparameters\n",
    "3. Fit the model to the training data\n",
    "4. Use the model to predict labels for new data \n",
    "\n",
    "The first two pieces of this - the choice of model and choice of hyperparameters are perhaps the most\n",
    "important part of using these tools and techniques effectively. In order to make an informed choice, we need a way to *validate* that our model and our hyperparameters are a good fit to the data. While this may sound simple, there are some pitfalls that you must avoid to do this effectively."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Thinking about Model Validation\n",
    "\n",
    "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "The following sections first show a naive approach to model validation and why it fails, before exploring the use of houldout sets and cross-validation for more robust model evaluation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}