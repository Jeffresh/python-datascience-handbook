{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Structured Data: NumPy's Structured Arrays\n",
    "\n",
    "While often our data can be well represented by a homogeneous array of values, sometimes this is not the case. This section demosntrates the use of NumPy's structured arrays and record arrays, which provide efficient storage for compound, heterogeneous data. While hte patterns shown here are useful for siple operations, scenarios like this often len themselves to the use of Pandas `Dataframe`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Imagine that we have several categories of data on a number of people (say, name, age, and weight), and we'd like to store these values for use in a Python program. It would be possible to store these in three separate arrays:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Alice', 'Bob', 'Cathy', 'Doug']\n",
    "age = [25, 45, 37, 19]\n",
    "weight = [55.0, 85.5, 68.0, 61.5]"
   ]
  },
  {
   "source": [
    "But this is a bit clumsy. There's nothing here that tells us that the three arrays are related; it would be more natural if we could use a single structure to store all of this data. NumPy can handle htis through structured arrays, which are arrays with compound data types.\n",
    "\n",
    "Recall that previoysly we created a simple array using an expression like this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(4, dtype=int)"
   ]
  },
  {
   "source": [
    " We can similarly create a structured array using a compound data type specification:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')]\n"
     ]
    }
   ],
   "source": [
    "# Use a compound data type for structured arrays\n",
    "data = np.zeros(4, dtype={'names':('name', 'age', 'weight'),\n",
    "                          'formats':('U10', 'i4', 'f8')})\n",
    "print(data.dtype)                          "
   ]
  },
  {
   "source": [
    "Here `U10` translates to \"Unicode string of maximum length 10\", `i4` translates to \"4-byte integer\", and `f8` translates to \"8-byte float\". We'll discuss other options for these types codes in the following section.\n",
    "\n",
    "Now that we've created an empty container array, we can fill the array with our lists of values:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('Alice', 25, 55. ) ('Bob', 45, 85.5) ('Cathy', 37, 68. )\n ('Doug', 19, 61.5)]\n"
     ]
    }
   ],
   "source": [
    "data['name'] = name\n",
    "data['age'] = age\n",
    "data['weight'] = weight \n",
    "print(data)"
   ]
  },
  {
   "source": [
    "As we had hoped, the data is now arranged together in one convenient block of memory.\n",
    "\n",
    "The handy thing with structured arrays is that you can now refer to values either by index or by name:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Alice', 'Bob', 'Cathy', 'Doug'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data['name']"
   ]
  },
  {
   "source": [
    "Get the name from the last row"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Doug'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data[-1]['name']"
   ]
  },
  {
   "source": [
    "Using Boolean masking, this even allows you to do some more sophisticated operations such as filtering on age:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Alice', 'Doug'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Get names where age is under 30\n",
    "data[data['age'] < 30]['name']"
   ]
  },
  {
   "source": [
    "Note that if you'd like to do any operations that are any more complicated than these, you should probably consider the Pandas package. Pandas provide a `Dataframe` object, which is a structure built on NumPy arrays that offers a variaty of useful data manipulation functionality similar to what we've shown here, as well as much, much more."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating Structured Arrays\n",
    "\n",
    "Structured array data types can be specified in a number of ways. Earlier, we saw the dictionary method:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype([('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.dtype({'names':('name', 'age', 'weight'), 'formats': ('U10', 'i4', 'f8')})"
   ]
  },
  {
   "source": [
    "For clarity, numerical types can be specified using Python types or NumPy `dtype` instead:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dtype({'names':('name', 'age', 'weight'), 'formats': ((np.str_, 10), int, np.float32)})"
   ]
  },
  {
   "source": [
    "A compound type can also be specified as a list of tuples:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "np.dtype([('name', 'S10'), ('age', 'i4'), ('weight', 'f8')])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "The shortened string format codes may seem confusin, but they are built on simple principles. The first (optional) characters is `<` or `>`, which means \"little endian\" or \"big endian\" and specifies the ordering convenction for significant bits.\n",
    "\n",
    "The next character specifies the type of data: characters, bytes, ints, floating points, and so on. The last character or characters represents the size of the object in bytes.\n",
    "\n",
    "```\n",
    "Character \tDescription \tExample\n",
    "'b' \tByte \tnp.dtype('b')\n",
    "'i' \tSigned integer \tnp.dtype('i4') == np.int32\n",
    "'u' \tUnsigned integer \tnp.dtype('u1') == np.uint8\n",
    "'f' \tFloating point \tnp.dtype('f8') == np.int64\n",
    "'c' \tComplex floating point \tnp.dtype('c16') == np.complex128\n",
    "'S', 'a' \tString \tnp.dtype('S5')\n",
    "'U' \tUnicode string \tnp.dtype('U') == np.str_\n",
    "'V' \tRaw data (void) \tnp.dtype('V') == np.void\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# More Advanced Compound Types\n",
    "\n",
    "It is possible to define even more advanced compund types. For example, you can create a type where each element contains an array or matrix of values. Here, we'll create a data type with a `mat` component consisting of a *3 x 3* floating-point matrix:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tp = np.dtype([('id', 'i8'), ('mat', 'f8', (3, 3))])\n",
    "X = np.zeros(3, dtype=tp)\n",
    "print(X[0])\n",
    "print(X['mat'][0])"
   ]
  },
  {
   "source": [
    "Now each element in the `x` array consist of an `id` and a *3 x 3* matrix. Why would you use this rather than a simple multidimensional array, or perhaps a Python dictionary? The reason is that this NumPy `dtype` direclty maps onto a C structure definiton, so the buffer containing the array content can be accessed directly within an appropriately written C program. If you find yourself writing a Pythin inferface to a legacy C or Fortran library that manipulates structured data, you'll probably find structured arrays quite useful!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# RecordArrays: Structured Arrays with a Twist\n",
    "\n",
    "NumPy also provides the `np.recarray` class, which is almost identical to the structured darrays just described, but with one additional feature: fields can be accessed as attributes rather than as dictionary keys. Recall that we previously accessed the ages by writing:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([25, 45, 37, 19])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "data['age']"
   ]
  },
  {
   "source": [
    "If we view our data as a record array instead, we can access this with slightly fewer keystrokes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([25, 45, 37, 19])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "data_rec = data.view(np.recarray)\n",
    "data_rec.age"
   ]
  },
  {
   "source": [
    "The down side is that for record arrays, there is some extra overhead involved in accessing the fields, even when using the same syntax. We can see this here:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "197 ns ± 59.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "3.24 µs ± 1.21 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "3.4 µs ± 609 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit data['age']\n",
    "%timeit data_rec['age']\n",
    "%timeit data_rec.age"
   ]
  },
  {
   "source": [
    "Where the more convenient notation is worth the addicitonal overhead will depend on your own application"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## On to Pandas\n",
    "\n",
    "This section on structured and record arrays is purposely at the end of this chapter,\n",
    "becasue it leads so well into the next package we will cover: Pandas. Structured array like the ones discussed here are good to know about for certain situations, especially in case you're using NumPy arrays to map onto binary data formats in C, Fortran, or another language. For day-to-day use of structured data, the Pandas package is a much better choice, and we'll dive into a full discussion of it in the chapter that follows."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}